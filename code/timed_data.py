"""
Process time data set
Expect to find set of files created by uw/data/timed_data/create_timed_data to generate files with times for all 
Extract a single data set around a cone with TimedData
"""

import os, glob, pickle
import healpy
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from astropy.time import Time, TimeDelta
from astropy.coordinates import SkyCoord

mission_start = Time('2001-01-01T00:00:00', scale='utc')

def MJD(met):
    # convert MET to MJD
    return (mission_start+TimeDelta(met, format='sec')).mjd

class TimedData(object):
    """Create a data set at a given position
    """
 
    plt.rc('font', size=12)
    
    def __init__(self, name, skycoord=None,  radius=5, 
            file_pattern='$FERMI/data/P8_P305/time_info/month_*.pkl'):
        """Set up combined data from set of monthly files

        name :    string, source name 
        skycoord : a SkyCoord object [optional, if not present use name to look up] 
        radius :  float, cone radius for selection [deg]
        file_pattern : string for glob use 
        """
        if skycoord is None:
            skycoord = SkyCoord.from_name(name)
        gal = skycoord.galactic
        l,b = (gal.l.value, gal.b.value)
        print(f'Selected position: (l,b)=({l:.1f},{b:.1f}), radius={radius}')
        self.l, self.b,self.radius=l,b,radius

        files = sorted(glob.glob(os.path.expandvars(file_pattern)))
        assert len(files)>0, 'No files found using pattern {}'.format(file_pattern)
        self.name = name
        gbtotal = np.array([os.stat(filename).st_size for filename in files]).sum()/2**30
        print(f'Reading {len(files)} files, with {gbtotal:.1f} GB total')

        dflist=[]

        for filename in files:
            dflist.append(self._load_timedata(filename,l,b, radius=radius))
            print('.', end=' ')
        self.df = pd.concat(dflist)
        print(f'Selected {len(self.df)} photons within {radius} deg of "{name}"')

    def _load_timedata(self, filename, l,b, radius, nside=1024):
        """Read in, process a file generated by binned_data.ConvertFT1.time_record
        
        return DataFrame with times, band id, distance from center
            
        parameters:
            filename : string
            l,b : position in Galactic 
            radius : cone radius, deg
            nside : for healpy

        returns:
            DataFrame with columns:
                band : from input, energy and event type  
                time : Mission Elapsed Time in s. (double)
                delta : distance from input position (deg, float32)
        """       
      
        with open(filename,'rb') as f:
            d = pickle.load( f ,encoding='latin1')
            tstart = d['tstart']
            df = pd.DataFrame(d['timerec'])
        # cartesian vector from l,b for healpy stuff    
        cart = lambda l,b: healpy.dir2vec(l,b, lonlat=True) 
        
        # use query_disc to get photons within given radius of position
        center = healpy.dir2vec(l,b, lonlat=True) #cart(l,b)
        ipix = healpy.query_disc(nside, cart(l,b), np.radians(radius), nest=False)
        incone = np.isin(df.hpindex, ipix)

        # times: convert to double, add to start
        t = np.array(df.time[incone],float)+tstart

        # convert position info to just distance from center             
        ll,bb = healpy.pix2ang(nside, df.hpindex[incone],  nest=False, lonlat=True)
        t2 = np.array(np.sqrt((1.-np.dot(center, cart(ll,bb)))*2), np.float32) 

        return pd.DataFrame(np.rec.fromarrays(
            [df.band[incone], t, np.degrees(t2)], names='band time delta'.split()))
    
    def write(self, filename):
        """ write to a file
        """
        out = dict(
            name=self.name, 
            galactic=(self.l,self.b), 
            radius=self.radius,
            time_data=self.df.to_records(index=False),
        )
        
        pickle.dump(out, open(filename, 'wb'))

    def plot_time(self, delta_max=2, delta_t=1, xlim=None):
        """
        """
        df = self.df

        t = MJD(df.time)
        ta,tb=t[0],t[-1]
        Nbins = int((tb-ta)/float(delta_t))

        fig,ax= plt.subplots(figsize=(15,5))
        hkw = dict(bins = np.linspace(ta,tb,Nbins), histtype='step')
        ax.hist(t, label='E>100 MeV', **hkw)
        ax.hist(t[(df.delta<delta_max) & (df.band>0)], label='delta<{} deg'.format(delta_max), **hkw);
        ax.set(xlabel=r'$\mathsf{MJD}$', ylabel='counts per {:.0f} day'.format(delta_t))
        if xlim is not None: ax.set(xlim=xlim)
        ax.legend()
        ax.set_title('{} counts vs. time'.format(self.name))

    def plot_delta(self, cumulative=False, squared=True):
        plt.rc('font', size=12)
        df = self.df
        fig,ax = plt.subplots(figsize=(6,3))
        x = df.delta**2 if squared else df.delta
        hkw = dict(bins=np.linspace(0, 25 if squared else 5, 100), 
                   histtype='step',lw=2,cumulative=cumulative)
        ax.hist(x, label='E>100 MeV', **hkw)
        ax.hist(x[df.band>8], label='E>1 GeV', **hkw)
        ax.set(yscale='log', xlabel='delta**2 [deg^2]' if squared else 'delta [deg]', 
            ylabel='cumulative counts' if cumulative else 'counts'); 
        ax.legend(loc='upper left' if cumulative else 'upper right');


### Code that must be run in FermiTools context to create the database
#from uw/data import binned_data
# def create_timed_data(
#         monthly_ft1_files='/afs/slac/g/glast/groups/catalog/P8_P305/zmax105/*.fits',
#         outfolder='$FERMI/data/P8_P305/time_info/',
#         overwrite=False  ):
#     """
#     """
#     files=sorted(glob.glob(monthly_ft1_files))
#     assert len(files)>0, 'No ft1 files found at {}'.format(monthly_ft1_files)
#     gbtotal = np.array([os.stat(filename).st_size for filename in files]).sum()/2**30
#     print '{} FT1 files found, {} GB total'.format(len(files), gbtotal)
#     outfolder = os.path.expandvars(outfolder)
#     if not os.path.exists(outfolder):
#         os.makedirs(outfolder)
#     os.chdir(outfolder)   
#     for filename in files:
#         m = filename.split('_')[-2]
#         outfile = 'month_{}.pkl'.format(m)
#         if not overwrite and os.path.exists(outfile) :
#             print 'exists: {}'.format(outfile)
#             continue
#         print 'writing {}'.format(outfile),
#         tr = binned_data.ConvertFT1(filename).time_record()
#         pickle.dump(tr, open(outfile, 'w'))
